{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNXF0nFNPH6H1vvjTB7v1k/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"GdnqZjLdaBgT"},"outputs":[],"source":["! pip install --user --upgrade requests bs4 pandas"]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","\n","url = \"https://readwrite.com/\" #해외 IT 전문 미디어\n","r = requests.get(url)\n","soup = BeautifulSoup(r.content, \"html.parser\")"],"metadata":{"id":"weXt8cTb4wid"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# category별 url 뽑기\n","categories = dict()\n","not_more = soup.find('div', {\"class\": \"menu-main-menu-container\"}).find_all('a') # 더보기를 안눌러도 볼 수 있는 categories\n","for a in not_more:\n","  if 'category' in a[\"href\"]:\n","    #categories.append((a.text, a[\"href\"]))\n","    categories[a.text] = a[\"href\"]\n","\n","more = soup.find_all(\"div\", {\"class\": \"col-md-12\"})[:2] # 더보기를 누르면 볼 수 있는 categories\n","for div in more:\n","  a_list = div.find_all('a')\n","  for a in a_list:\n","    if 'category' in a[\"href\"]:\n","      #categories.append((a.text, a[\"href\"]))\n","      category_name = a.text; category_url = a[\"href\"]\n","      if '/' in category_name:\n","        category_name = category_name.replace('/', '_')\n","      categories[category_name] = category_url\n","#####\n","print(categories)\n","# categories_list = list(categories)[:18]\n","# for c in categories_list:\n","#   del(categories[c])\n","# print(categories)\n","#####"],"metadata":{"id":"jOGtrV2c758F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# html 파일 크롤링\n","\n","from google.colab import drive\n","import time\n","\n","drive.mount('/content/drive')\n","path = \"/content/drive/Shared drives/PythonCoaching_2023Summer\"\n","my_folder = \"ljw33083418\"\n","outcome_folder = f\"{path}/{my_folder}/outcome/project/htmls\"\n","\n","for key, value in categories.items():\n","\n","  r_category = requests.get(value)\n","  soup_category = BeautifulSoup(r_category.content, \"html.parser\")\n","  navigation = soup_category.find(\"div\", {\"class\": \"post-navigation\"}).find('ul').find_all('li')\n","  max_pagenum = int(navigation[-2].find('a').text)\n","\n","  file_name = key + '_'\n","\n","  if key == 'Web':\n","    for i in range(623, max_pagenum+1): #해당 category에 대한 모든 page\n","\n","      r_page = requests.get(value + \"page/\" + str(i))\n","      soup_page = BeautifulSoup(r_page.content, \"html.parser\")\n","\n","      articles = soup_page.find_all(\"h2\", {\"class\": \"entry-title\"}) #여기서 앞의 20개 article들은 most popular article들로, page에 관계 없이 계속 반복됨\n","      articles = articles[20:]\n","\n","      for article in articles:\n","        try:\n","          article = article.find('a')\n","          title = article.text; url = article[\"href\"]\n","\n","          r_article = requests.get(url)\n","\n","          file_name += url[len(\"https://readwrite.com/\"):-1] + \".html\"\n","          with open(f\"{outcome_folder}/{file_name}\", \"w+b\") as fw:\n","              fw.write(r_article.content)\n","          file_name = key + '_'\n","        except Exception as e:\n","          print(f\"An error occurred for {url}: {e}\")\n","        time.sleep(1)\n","\n","  else:\n","    for i in range(1, max_pagenum+1): #해당 category에 대한 모든 page\n","\n","      r_page = requests.get(value + \"page/\" + str(i))\n","      soup_page = BeautifulSoup(r_page.content, \"html.parser\")\n","\n","      articles = soup_page.find_all(\"h2\", {\"class\": \"entry-title\"}) #여기서 앞의 20개 article들은 most popular article들로, page에 관계 없이 계속 반복됨\n","      articles = articles[20:]\n","\n","      for article in articles:\n","        try:\n","          article = article.find('a')\n","          title = article.text; url = article[\"href\"]\n","\n","          r_article = requests.get(url)\n","\n","          file_name += url[len(\"https://readwrite.com/\"):-1] + \".html\"\n","          with open(f\"{outcome_folder}/{file_name}\", \"w+b\") as fw:\n","              fw.write(r_article.content)\n","          file_name = key + '_'\n","        except Exception as e:\n","          print(f\"An error occurred for {url}: {e}\")\n","        time.sleep(1)"],"metadata":{"id":"73p_oiLV66XT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 정규표현식 테스트\n","import re\n","\n","input_string = \"This is a test string with extra spaces. author: John Doe\"\n","author = \"John Doe\"\n","pattern = re.escape(author)\n","output_string = re.sub(pattern, '', input_string)\n","print(output_string)"],"metadata":{"id":"OWcaWG53Qn4N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# html files read\n","\n","from google.colab import drive\n","import os\n","import re\n","\n","drive.mount('/content/drive')\n","path = \"/content/drive/Shared drives/PythonCoaching_2023Summer\"\n","my_folder = \"ljw33083418\"\n","outcome_folder = f\"{path}/{my_folder}/outcome/project/\"\n","\n","html_files = [file for file in os.listdir(f\"{outcome_folder}/htmls\") if file.endswith(\".html\")]\n","html_files = list(set(html_files))\n","html_files.sort()\n","total_files_length = len(html_files) #28245"],"metadata":{"id":"xS4gHwRRkxtZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# html_data.csv 생성\n","\n","with open(f\"{outcome_folder}/html_data.csv\", \"a\") as fw:\n","  #fw.write(\"category\\ttitle\\tauthor\\ttimestamp\\tbody\\n\")\n","  for i in range(4727, total_files_length):\n","    file_name = html_files[i]\n","    with open(f\"{outcome_folder}/htmls/{file_name}\", \"r+b\") as fr:\n","      soup = BeautifulSoup(fr.read(), \"html.parser\")\n","\n","      categories = set()\n","      origin_cat = file_name.split('_')[0]\n","      if origin_cat == 'AR_VR':\n","        origin_cat = 'AR/VR'\n","      categories.add(origin_cat)\n","\n","      category_hrefs = soup.find(\"span\", {\"class\": \"author catname\"})\n","      if category_hrefs:\n","        category_hrefs = category_hrefs.find_all(\"a\")\n","      if category_hrefs:\n","        for href in category_hrefs:\n","          if href.text == 'ReadWrite':\n","            continue\n","          categories.add(href.text)\n","\n","      title = soup.find(\"h1\", {\"class\": \"entry-title\"})\n","      if title: title = title.text\n","      else: continue\n","\n","      author = soup.find(\"span\", {\"class\": \"author\"})\n","      if author: author = author.find('a').text.replace('\\n', ' ').replace('\\t', ' ').replace('\\xa0', ' ').replace('\\u200a', ' ').strip()\n","      else: continue\n","\n","      timestamp = soup.find(\"span\", {\"class\": \"post-cat\"})\n","      if timestamp: timestamp = timestamp.text.replace('\\n', ' ').replace('\\t', ' ').replace('\\xa0', ' ').replace('\\u200a', ' ').strip()\n","      else: continue\n","\n","      body = soup.find(\"div\", {\"class\": \"entry-content col-md-10\"})\n","      if body: body = body.text.replace('\\n', ' ').replace('\\t', ' ').replace('\\xa0', ' ').replace('\\u200a', ' ').strip()\n","      else: continue\n","\n","      match_index = re.search(author, body)\n","      if match_index:\n","        start_index = match_index.start()\n","        body = body[:start_index]\n","      body = body.strip()\n","\n","\n","      if categories and title and author and timestamp and body:\n","        fw.write(f\"{categories}\\t{title}\\t{author}\\t{timestamp}\\t{body}\\n\")\n","\n","      print(str(i)+'/'+str(total_files_length))"],"metadata":{"id":"02V96j-D7-XY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","path = \"/content/drive/Shared drives/PythonCoaching_2023Summer\"\n","my_folder = \"ljw33083418\"\n","outcome_folder = f\"{path}/{my_folder}/outcome/project/\"\n","\n","pd.set_option('display.max_colwidth', 150)\n","\n","df_who = pd.read_csv(f\"{outcome_folder}/html_data.csv\", sep=\"\\t\", lineterminator='\\n')\n","df_who"],"metadata":{"id":"KeqPIHKgJJLk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_who.info()"],"metadata":{"id":"p6ZfGPuZRjMX"},"execution_count":null,"outputs":[]}]}